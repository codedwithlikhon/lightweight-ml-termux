"""
Deploy TinyMLP to Hugging Face Spaces
Automatically creates and configures a Space
"""

import os
import sys
from huggingface_hub import HfApi
import subprocess

def create_space():
    """Create and upload to Hugging Face Spaces"""

    print("ğŸš€ Starting Hugging Face Spaces Deployment")
    print("="*60)

    # Initialize HF API (uses gh token)
    api = HfApi()
    print("âœ… Hugging Face API initialized")

    # Space configuration
    space_id = "tiny-mlp-ultra-lightweight"
    username = "codedwithlikhon"
    repo_id = f"{username}/{space_id}"
    private = False  # Public space for easy access

    print(f"\nğŸ“¦ Space Details:")
    print(f"   ID: {space_id}")
    print(f"   Repository: {repo_id}")
    print(f"   Visibility: {'Private' if private else 'Public'}")

    # Check if Space already exists
    print("\nğŸ” Checking if Space exists...")
    try:
        api.repo_info(repo_id=repo_id)
        print("âš ï¸  Space already exists!")
        print(f"   URL: https://huggingface.co/spaces/{repo_id}")
        choice = input("   Do you want to update it? (y/n): ")
        if choice.lower() != 'y':
            print("âŒ Deployment cancelled")
            return
    except Exception as e:
        print(f"âœ… Space does not exist, will create new one")

    # Create Space
    print("\nğŸ—ï¸  Creating Space...")
    try:
        api.create_repo(
            repo_id=repo_id,
            repo_type="space",
            private=private,
            space_sdk="gradio"  # We'll use Gradio
        )
        print(f"âœ… Space created: {repo_id}")
    except Exception as e:
        print(f"âŒ Failed to create Space: {e}")
        return

    # Create Space-specific files
    print("\nğŸ“ Creating Space configuration...")

    # app.py is already created
    # requirements.txt is already created
    # Create README.md for Space
    readme_content = """# TinyMLP - Ultra-Lightweight ML

ğŸ¤– **Ultra-Lightweight Neural Network (0.20 MB)**

Trained entirely on Android Termux!

## Model Info
- **Architecture**: Multi-Layer Perceptron (784 â†’ 64 â†’ 32 â†’ 10)
- **Parameters**: 52,650
- **Model Size**: 0.20 MB
- **Training**: Mobile CPU (Android Termux)
- **Inference Time**: < 50ms

## Live Demo
Visit the app tab above to test predictions!

## API
```bash
curl https://huggingface.co/spaces/{repo_id}/predict -X POST
```

## Training Details
- Framework: PyTorch 2.6.0
- Dataset: Synthetic (28x28 features)
- Optimizer: Adam (lr=0.01)
- Training Time: ~3 seconds
- Memory: Minimal (CPU, batch size 32)

## Philosophy
> "Beautiful is better than ugly. Simple is better than complex."

Built for mobile-first ML deployment with zero vendor lock-in.

## Cost
- CPU Basic: **FREE** âœ…
- Storage: ~1 MB
- Inference: $0

---
*Deployed from Android Termux* ğŸ“±
"""

    # Write README
    with open("README_spaces.md", "w") as f:
        f.write(readme_content)

    # Upload files
    print("\nğŸ“¤ Uploading files to Space...")

    files_to_upload = [
        "app.py",
        "requirements-spaces.txt",
        "models/tiny_mlp.pth",
        "models/tiny_mlp_metadata.yaml",
        "README_spaces.md"
    ]

    for file_path in files_to_upload:
        if os.path.exists(file_path):
            api.upload_file(
                path_or_fileobj=open(file_path, "rb").read(),
                path_in_repo=file_path,
                repo_id=repo_id
            )
            print(f"   âœ… Uploaded: {file_path}")
        else:
            print(f"   âš ï¸  Not found: {file_path}")

    print("\n" + "="*60)
    print("ğŸ‰ Deployment Complete!")
    print("="*60)
    print(f"ğŸŒ Space URL: https://huggingface.co/spaces/{repo_id}")
    print(f"ğŸ“± Your ultra-lightweight model is now live!")
    print("="*60)

if __name__ == "__main__":
    create_space()